Improving a single aspect of a computer does not lead to a proportional improvement in overall performance

$$
T_\text{improved} = \frac{T_\text{improved}}{\text{improvement factor}} + T_\text{unaffected}
$$
Ex. In a 100-second program, multiplication accounts for 80 seconds. How much improvement in multiplication performance do we need to get 5x overall improvement
- 5 x improvement => new total time =  20 seconds
	- $$ 20 = \frac{80}{n} + 20$$
	- Cant be done!!!